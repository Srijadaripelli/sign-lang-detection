PROJECT DESCRIPTION
Real-time Sign Language Detection system that recognizes hand gestures and translates them into readable text. 
It is designed to assist people with hearing or speech impairments by providing a seamless way to communicate using sign language.

--Usage--
Run the detect.py script.
Show a sign language gesture in front of the camera.
The model will detect and display the corresponding text on the screen.

--Technologies Used--
Python (Core programming language)
OpenCV (For image processing and webcam integration)
TensorFlow/Keras (For training deep learning models)
MediaPipe (For hand tracking and feature extraction)
NumPy & Pandas (For data manipulation)

--Challenges & Future Enhancements--
Expand Support for More Languages (Currently supports ASL/ISL).
Improve Gesture Recognition Accuracy.
Deploy as a Web or Mobile Application.
Add Audio Output for Recognized Text.
